\chapter{Results}

\section{Hardware}
The hardware used to produce the results is the Samsung Nexus S (cobranded with
Google) running Android 2.3.4. The official specifications of the device can be
obtained from the manufacturer's website [link to website with reference] A
short listing of the sensors present on the device is given below based on how
the device reports the sensors via the software APIs:

\begin{enumerate}
\item KR3DM 3-axis Accelerometer
\item AK8973 3-axis Magnetic field sensor
\item AK8973 Orientation sensor
\item GP2A Light sensor
\item GP2A Proximity sensor
\item K3G Gyroscope sensor
\item Gravity Sensor
\item Linear Acceleration Sensor
\item Rotation Vector Sensor
\end{enumerate}

It may be noted that of these sensors, the Gravity sensor, the Linear
Acceleration Sensor and the Rotation Vector Sensor are derived sensors. They
depend on filtering the raw data sensed via the accelerometer and the
magnetometer to generate their sensed values. In essence, the Gravity sensor is
a low pass filter over the accelerometer values (since gravity is essentially
stable for the device at a particular orientation), the Linear Acceleration
Sensor is a high pass filter over the accelerometer values (the high frequency
changes in acceleration are presumed to occur due to device motion and thus
correspond to linear acceleration of the device) and the Rotation Vector Sensor
is a composite sensor that fuses Gravity information derived from the
3 axis Accelerometer and the magnetic field information derived from the
3 axis Magnetic field sensor to orient the device in the 3 Dimensional World 
Coordinate space. The actual method used to do so is described in the API
documentation \todo{Provide Reference}[reference to API documentation] and
further discussion is out of scope for this thesis.

\begin{figure}
\centering
    \includegraphics[height=3in]{figures/android_front}
    \includegraphics[height=3in]{figures/android_back}
\caption{Google Nexus S manufactured by Samsung}
\end{figure}

\section{Location Under Test}

The location chosen for performing all experimental verification of the
proposed work was Floor 3, Wing 6 and 7 of Ravindra Bhawan at the IIT Roorkee
campus. The environment is suitable for this purpose due to a number of reasons:

\begin{enumerate}
\item There are a large number of Wifi Access Points in close proximity 
    installed on the premises.
\item Wifi Access Points of neighbouring wings and floors provide diversity
    to the location fingerprints.
\item Long corridoors of around 30-32 metres each provide long stretches of
    similar environment for evaluation of algorithm performance over larger
    distances.
\end{enumerate}

A map of the location is shown in Figure \ref{fig:ravindra_map}. The red lines
indicate walls, blue lines indicate windows and green lines indicate doors.
Wifi Access Points are marked with stars on the map. This map has been used
for all the experiments detailed below.

\begin{figure}
    \centering
    \includegraphics[width=6in]{figures/ravindra_map.png}
    \caption{A map of the experimental environment\label{fig:ravindra_map}}
\end{figure}



\section{Step detection procedure}

Step detection for dead reckoning was done using accelerometer sensor data.
Two different methods were employed and the simple zero crossing method on 
unfiltered data was used as control to estimate the increase in accuracy of the
step detection procedure. A simple clamping technique was employed to filter the
raw acceleration as described in Section \ref{sec:NoiseClamping}.

The effect of the clamping on the raw accelerometer data is shown in 
Figure \ref{fig:accel_raw}. Figure \ref{fig:accel_diff} shows the sensor noise
that is rejected around zero enabling clean detection of peaks corresponding to
the steps.

The comparative graph of the performance of the step detection procedures 
is shown in Figure \ref{fig:csteps}. The correspondence to the ground truth
is shown in Table \ref{tbl:step_table}.

\begin{table}[tbph]
\centering
\begin{tabular}{||l|c||}
\hline
\hline
\textbf{Algorithm} & \textbf{Steps Detected} \\
\hline

Simple Zero Crossings Count & 109 \\
Zero Crossings on Filtered Data & 41 \\
Peaks and Valley Method & 41 \\
\textbf{Ground Truth} & \textbf{40} \\
\hline
\hline
\end{tabular}
\caption{Step Detection Performance\label{tbl:step_table}}
\end{table}

It can be seen that a simple Zero Crossing method performs similarly to the 
Peaks and Valley method. From the time based graph plotted in 
Figure \ref{fig:csteps}, it can be seen that the Peaks and Valley method 
slightly lags the Zero Crossing method in time. This is to be expected as this
method detects a step only when the next peak is detected and thus suffers a 
lag of about half a step.

\begin{figure}[tbph]
    \centering
    \includegraphics{figures/csteps.png}
    \caption{Performance of Step Detection Algorithms\label{fig:csteps}}
\end{figure}

\begin{figure}[tbph]
    \centering
    \includegraphics{figures/accel_raw.png}
    \caption{Performance of the Filtering algorithm \label{fig:accel_raw}}
\end{figure}

\begin{figure}[tbph]
    \centering
    \includegraphics{figures/accel_diff.png}
    \caption{Rejected signal from the Accelerometer sensor \label{fig:accel_diff}}
\end{figure}


\section{First Fix}

For any dead reckoning algorithm, it is important to provide a good starting
point. Low error in the starting location contributes to better
tracking performance.

In order to provide the starting point to the algorithm two approaches were
implemented:

\begin{enumerate}
\item Directly choose the starting location on a map using the capacitive 
    touchscreen
\item Select the starting location based on QRCode recognition using the onboard
    camera. The QRCodes were printed and pasted at specific locations 
    in the area under test.
\end{enumerate}

\missingfigure{QRCodes pasted on the wall}

\subsection{Experimental setup}

All the experments were performed with the same Android device (the Samsung 
Nexus S) and with the same application software. Users were familiar with 
touch screen phones and were well aware of the layout of the building. None of
the users had had any prior exposure to the map of the building and did not 
know the direction of True North. Details of the experiments performed 
are specified in Sections \ref{sec:direct_selection} and \ref{sec:qrcode_selection}

\subsection{Direct Selection of Location on a Map\label{sec:direct_selection}}

Five test subjects were asked to mark out their current position on a
map by simply touching the corresponding location on the map shown on the 
touchscreen of the device. The map was shown at a fixed resolution to all 
test subjects in order to make their responses comparable. 

The test were also allowed to retry locating themselves on the map in case they
were not satisfied with their initial results. All their location attempts were
logged for later analysis.The following facts were observed during the process of 
selection:

\begin{enumerate}
\item Users had an initial difficulty in orienting themselves with regard to 
    the map supplied.
\item As the map contained blocks of rooms that were similar looking, users
    made initial errors in orienting themselves. However, they attempted to 
    correct their errors when the mistake was realized.
\item Some users felt extremely frustrated by the direct selection procedure
    primarily because they could not mark out their locations precisely due
    to the large surface area of contact of their fingers with the touch
    screen. The variability of selection of the contact point while using 
    the touchscreen contributed to an increase in the number of attempts
    required to correctly mark their positions on the map.
\end{enumerate}

\todo[inline]{Ask 5 people to select locations on a map and log data}
\missingfigure{Table of error from true location}
\missingfigure{Table of number of times attempted for satisfactory positioning}

\subsection{Camera based QRCode Method \label{sec:qrcode_selection}}

To evaluate the efficiency of determining first fix via QRCodes in comparison 
to the direct location selection method, an experiment was set up. 
The experiment was performed in conjunction with the experment of 
Section \ref{sec:direct_selection}, users were asked to locate themselves
by snapping a QRCode pasted on the wall instead of marking their starting 
location on a map.

The users were then positioned at various distances from the QRCode and 
asked whether they would make the effort to go to the QRCode to snap their
starting location while using the application or whether they would prefer
the manual method.

The following observations were made regarding the QRCode method for first
fix:

\begin{enumerate}
\item QRCode selection via the camera was a fast process, usually not requiring
    more than 10 seconds on behalf of the user.
\item Users were consistently located at distances less than 1 meter from 
    the QRCode. In most cases, the users were at a distance of around 30 cm 
    from the QRCode pasted on the wall. 
\item There was an instance where poor lighting delayed the capture of the
    QRCode and the QRCode could be successfully captured only after a 
    fluorescent tubelight was switched on to provide adequate lighting.
\end{enumerate}

\missingfigure{Image of a person snapping the QRCode with the camera}

\subsection{Comparison between the two methods}

After processing the results of the experiments, it was determined that 
users overwhelmingly preferred the QRCode method for first fix acquisition.
They were willing to walk up to $5 m$ to the nearest QRCoded location in 
order to take advantage of the facility.

\todo[inline]{Insert survey results}

\subsection{User Feedback}

Users in their comments indicated that potential improvements to the 
application were possible. For example, if the application could determine 
roughly their current location and then provide just that subset of the map
in which the user was located, the speed of providing the first fix location 
by a manual method could be improved.

\section{Determining the Training Constant}

In a separate experiment, three test subjects were asked to walk between 
2 QRCoded locations. The first fix was taken using the QRCode method and 
the training constant was thus estimated based on the number of steps 
detected and the known distance between the 2 QRCoded locations.

The locations used for this test were along a corridoor and were about $30 m$
apart. The tests were repeated thrice for each subject. The resulting 
step constants are summarized in the table below.

\todo[inline]{Determining training constant}
\missingfigure{Table of training constant values}

\section{Step variation analysis}

To see the performance of the algorithm to step variations, an experiment 
was performed wherein a test subject walked at three distinct speeds
along a straight corridoor. The subject paused for a short while between 
the three distinct segments to maintain separation of speeds.

The three segments of the walk had the following
characteristics:

\begin{enumerate}
\item The test subject walked with very light steps, almost shuffling along. 
\item The test subject walked with regular steps along the corridoor.
\item The test subject walked with large steps along the corridoor in a motion
    that approximated running.
\end{enumerate}

The accelerometer graphs and the consequent step detections for this 
experiment are shown in Figure \ref{fig:step_variation}. The tabulated
results of the step detection process are shown in 
Table \ref{tbl:step_variation}. Note that the poor performance for 
shuffling steps is due to acceleration peaks not being sufficiently 
distinguishable from sensor noise and for the fast heavy steps is 
due to generation of spurious peaks while coming to an abrupt halt.
A smooth motion doesn't generate such issues and thus the step 
detection procedure is very accurate for that range.

\begin{table}[tbph]
    \centering
    \begin{tabular}{|l|c|c|}
        \hline
        \hline
        Step Segment & Actual Number of Steps & Steps Detected \\
        \hline
        Light Steps (Shuffle) & 10 & 5 \\
        Regular steps & 10 & 10 \\
        Fast (Heavy) steps & 15 & 18 \\
        \hline
        \hline
    \end{tabular}
    \caption{Step detections under step variations\label{tbl:step_variation}}
\end{table}

\begin{figure}
    \centering
    \includegraphics{figures/step_variation.png}
    \caption{Difference in step sizes and the corresponding variations in 
        step detection and step estimates\label{fig:step_variation}}
\end{figure}

\section{Test Paths}

Five different test paths were used to test the performance of the system.
The features of these paths are described below. The paths themselves
are marked out in Figure \ref{fig:test_paths}.

\begin{enumerate}
\item Straight walk down a corridoor (A to B)
\item Straight walk down a corridoor, a U turn followed by a straight walk 
    to the starting point. (A to B and then B to A)
\item Zig-Zag walk down a corridoor (A to B).
\item A U shaped walk along all three corridoors. (A-B-C-D)
\item A U shaped walk along all three corridoors followed by a U turn and a 
    walk back to the starting location. (A-B-C-D-C-B-A)
\end{enumerate}

\begin{figure}
    \centering
    \includegraphics[width=5in]{figures/test_paths.jpg}
    \caption{Test paths for algorithm\label{fig:test_paths}}
\end{figure}


\section{Simple Dead Reckoning}

As discussed in the Literature Review (Chapter \ref{chap:literature_review}) and
in the Proposed Work (Chapter \ref{chap:proposed_method}), it is impossible to
directly obtain displacement information by double integration of the
accelerometer data. Hence, the step detection method was employed for tracking
the motion of the device as held by a walking human. The steps are integrated
with orientation information received from the magnetometer to create a 
simple dead reckoning system in accordance with the dynamical equation 
\eqref{eq:dr_eq}. The initial position for dead reckoning was obtained via
QRCodes in accordance with the description in Section \ref{sec:QRCodes}.


\subsection{Simple Dead Reckoning Results}
\todo[inline]{Describe actual path and dead reckoning path}
\missingfigure{Dead Reckoning path}

\section{Plain Wifi Based Positioning}
\subsection{Case 1: Dead reckoning with NN wifi positioning}
\subsection{Case 2: Dead reckoning with KNN averaging}
\subsection{Case 3: Dead reckoning with clamped wifi positioning}

\section{Particle Filter Performance}
\subsection{Case 1: Probability of crossing walls is 0}
\subsection{Case 2: Probability of crossing walls is finite}
\subsection{Case 3: Resampling of impoverished data points with duplication}
\subsection{Case 4: Resampling with introduction of Gaussian noise}
\subsection{Case 4a: Use of averaged data points v/s random weighted data point}
\subsection{Case 5: Accounting for bias in orientation sensor}
\subsection{Case 6: Accounting for step size bias.}
\subsection{Case 7: Simple post processing of output.??}
\subsection{Case 8: Simple heuristics to deal with impoverished samples}
(retry, retry with greater inaccuracy)

\section{Signal Strength Map}

TODO if time permits
Wifi signal strength map developed using crowdsourced data for use in systems such as RedPin.

\section{Summary of Results}
\todo[inline]{Which algorithms to pick based on the results, advantages and disadvantages}

\section{Issues faced}
Incorrect step sizes yielded states in which no further progress was possible
using data from the inertial sensors. Hence we had to resort to wifi data to get
out of the blind spot.

Limited processing power and near-realtime time constraints of operation
constrain computational complexity of the solution.

Surveying is the biggest issue in this system.

Computational complexity and scaling issues.


\section{Future Work: Particle filter + Wifi data}

\subsection{Case 1: Use of Wifi data for accounting for drift errors}
\subsection{Case 2: Use of Oriented Wifi data for accounting for drift errors}
\subsection{Case 3: Use of clamped wifi data for accounting for drift errors}
\subsection{Case 4: Use of area Restricted Wifi data for accounting for drift errors}

